{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_FromSpring_dataset_task2_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx2zNj1HoohYvKwnp8W/Nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimasadiq/NLP_Module_Project_hatespeechdetection/blob/main/NLP_Project_FromSpring_dataset_task2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puD9wGabfus2"
      },
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "string.punctuation\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "#defining the object for stemming\n",
        "porter_stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNH1FM9WgLKv",
        "outputId": "6986fc8f-da4a-4057-9e5a-ce99a8888158"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bHiGx5nZgWKZ",
        "outputId": "31c73488-c6f9-4b69-bc23-12e046aba7d0"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ej4hVk9KgH8_",
        "outputId": "3c04b305-6874-4675-eb40-116531e46417"
      },
      "source": [
        "#text lower\n",
        "df[\"posts\"] = df[\"posts\"].str.lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "#storing the puntuation free text\n",
        "df['posts']= df['posts'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "#removing numbers \n",
        "def remove_numbers(text):\n",
        "  output=''.join(c for c in text if not c.isdigit())\n",
        "  return output\n",
        "#applying the function\n",
        "#text=this person 100 fake beware isabella\n",
        "df['posts']= df['posts'].apply(lambda x:remove_numbers(x))\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   i like too many songs to have a favorite      0\n",
              "1                                   haha jk       0\n",
              "2                         really thanks haha      0\n",
              "3                                                 0\n",
              "4                                       rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObMaI6ZXW2Uf"
      },
      "source": [
        "# LR and TFIDF after removing punctuations and numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAOGwNMZW5n4"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.metrics import f1_score ,classification_report ,accuracy_score\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_ppsW0wXEuQ"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['posts'], df['label'] , test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI-lIph-YNxp",
        "outputId": "38539c36-3870-47c7-ba3d-d7033ea3cc37"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPxOgsA1YmuZ"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'.')\n",
        "count_vect.fit(df['posts'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJnKo701XLHE",
        "outputId": "8a65a8ca-c644-485f-f2ad-85634e2a81ad"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['posts'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['posts'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['posts'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUL0WntZXSz2"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIJc4zV0aVUy",
        "outputId": "8aa7b0d5-29ed-4bfa-9fd2-a6ff7cc3beec"
      },
      "source": [
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR Accuracy, WordLevel TF-IDF: \", accuracy)\n",
        "print(\"LR F1score, WordLevel TF-IDF: \", f1score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR Accuracy, N-Gram Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR Accuracy, CharLevel Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Accuracy, WordLevel TF-IDF:  0.9544383346425765\n",
            "LR F1score, WordLevel TF-IDF:  0.9631488109815419\n",
            "LR Accuracy, N-Gram Vectors:  0.9375490966221524\n",
            "LR F1score, N-Gram Vectors:  0.9638774351120077\n",
            "LR Accuracy, CharLevel Vectors:  0.9560094265514533\n",
            "LR F1score, N-Gram Vectors:  0.9639191483409262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lsjwKeIcykJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nVWMaxLFc3cs",
        "outputId": "6790fec5-6581-491a-905e-cde45e505aa7"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpvVo9rNGJzF",
        "outputId": "2236a7f2-a3f6-4e39-a2a5-a84bd8e137c5"
      },
      "source": [
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nFJyL09riJv2",
        "outputId": "8d057f02-c779-4d37-b935-0957479b0764"
      },
      "source": [
        "#removing stop words\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: remove_stopwords(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tell guy gay seem super straight</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Idk I'm gay</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This person 100% fake beware Isabella!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Oof lmao fake? Who's lmao shit fuck speak like...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If loved one left n cut ties w u wait bc I sti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 q_a  label\n",
              "0                   tell guy gay seem super straight      0\n",
              "1                                        Idk I'm gay      0\n",
              "2             This person 100% fake beware Isabella!      1\n",
              "3  Oof lmao fake? Who's lmao shit fuck speak like...      1\n",
              "4  If loved one left n cut ties w u wait bc I sti...      0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAqTyzj-crQB"
      },
      "source": [
        "#Accuracy and F1score after stopwords removal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBWjep0Rcru5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.metrics import f1_score ,classification_report ,accuracy_score\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV82te12dDbX"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['posts'], df['label'] , test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O5ClIW_dJiW",
        "outputId": "612361ff-fe1e-4b53-bf7c-3b798369b5de"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZdPwIkwdSsx"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'.')\n",
        "count_vect.fit(df['posts'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XqImlP5dSsx",
        "outputId": "f7027dd0-bc81-4332-dba7-458503e6afcf"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['posts'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['posts'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['posts'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CBzuBiSdSsy"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMwMuerhdSsy",
        "outputId": "ea5bd36e-ea81-4003-b420-17c0c1289145"
      },
      "source": [
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR Accuracy, WordLevel TF-IDF: \", accuracy)\n",
        "print(\"LR F1score, WordLevel TF-IDF: \", f1score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR Accuracy, N-Gram Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR Accuracy, CharLevel Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Accuracy, WordLevel TF-IDF:  0.9528672427336999\n",
            "LR F1score, WordLevel TF-IDF:  0.963009402781837\n",
            "LR Accuracy, N-Gram Vectors:  0.9375490966221524\n",
            "LR F1score, N-Gram Vectors:  0.9645417287374761\n",
            "LR Accuracy, CharLevel Vectors:  0.9575805184603299\n",
            "LR F1score, N-Gram Vectors:  0.9654468904977279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRj1_eWvdyEF"
      },
      "source": [
        "#Accuracy and F1score after Stemming"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9gZzziTfdyn8",
        "outputId": "d5a7c3c1-4d0c-48f4-f86e-576687b48529"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WmzU6v2gjbRC",
        "outputId": "d7762042-39b6-4078-c295-f998f8ee28f0"
      },
      "source": [
        "#stemming\n",
        "def stem_words(text):\n",
        "    return \" \".join([porter_stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: stem_words(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too mani song to have a favorit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really?!?! thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*rawr*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    posts  label\n",
              "0  I like too mani song to have a favorit      0\n",
              "1                      </3 ? haha jk! <33      0\n",
              "2                really?!?! thanks?! haha      0\n",
              "3                                      ;(      0\n",
              "4                                 *rawr*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thHmkI8KeC7y"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.metrics import f1_score ,classification_report ,accuracy_score\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Z6fctReC7y"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['posts'], df['label'] , test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiXVCftyeC7y",
        "outputId": "4554de0f-44d6-4cd0-8808-468888fb8a67"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QesIwXigeC7z"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'.')\n",
        "count_vect.fit(df['posts'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0nI_LqqeC7z",
        "outputId": "ccbeb4ad-9acd-4ed2-dd2a-c71aa1ed7430"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['posts'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['posts'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['posts'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1OaaLuleC7z"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmpy85FPeC7z",
        "outputId": "85b064e1-8d7d-4e24-9f99-a76dc2941a96"
      },
      "source": [
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR Accuracy, WordLevel TF-IDF: \", accuracy)\n",
        "print(\"LR F1score, WordLevel TF-IDF: \", f1score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR Accuracy, N-Gram Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR Accuracy, CharLevel Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Accuracy, WordLevel TF-IDF:  0.9516889238020424\n",
            "LR F1score, WordLevel TF-IDF:  0.9616399573092366\n",
            "LR Accuracy, N-Gram Vectors:  0.9379418695993715\n",
            "LR F1score, N-Gram Vectors:  0.964432745642087\n",
            "LR Accuracy, CharLevel Vectors:  0.9552238805970149\n",
            "LR F1score, N-Gram Vectors:  0.9643118800503233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYHToJVgErW"
      },
      "source": [
        "#Accuracy and F1score after applying all the preprocessing steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K8lVY4H3fxo9",
        "outputId": "b4106b69-f926-4c32-8785-b0a76ba35e0b"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVjo_x3fzDr"
      },
      "source": [
        "#by applying all the preprocessing steps at once"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Inbi628TgLso",
        "outputId": "a1a04b6e-c1ab-49b2-95b4-2078a290ff55"
      },
      "source": [
        "#text lower\n",
        "df[\"posts\"] = df[\"posts\"].str.lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "#storing the puntuation free text\n",
        "df['posts']= df['posts'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "#removing numbers \n",
        "def remove_numbers(text):\n",
        "  output=''.join(c for c in text if not c.isdigit())\n",
        "  return output\n",
        "#applying the function\n",
        "#text=this person 100 fake beware isabella\n",
        "df['posts']= df['posts'].apply(lambda x:remove_numbers(x))\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   i like too many songs to have a favorite      0\n",
              "1                                   haha jk       0\n",
              "2                         really thanks haha      0\n",
              "3                                                 0\n",
              "4                                       rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1HjOHBHHgLso",
        "outputId": "f35313a9-77b5-4ca8-b28f-8fd8e9c5f4c4"
      },
      "source": [
        "#removing stop words\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: remove_stopwords(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like many songs favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      posts  label\n",
              "0  like many songs favorite      0\n",
              "1                   haha jk      0\n",
              "2        really thanks haha      0\n",
              "3                                0\n",
              "4                      rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PVDb4VDQv5LT",
        "outputId": "95c763ff-67ba-49fb-f6cc-ffbf4b1b0fd4"
      },
      "source": [
        "dfb =df[['label' ,'posts']]\n",
        "dfb.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>like many songs favorite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>haha jk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>really thanks haha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>rawr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                     posts\n",
              "0      0  like many songs favorite\n",
              "1      0                   haha jk\n",
              "2      0        really thanks haha\n",
              "3      0                          \n",
              "4      0                      rawr"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mlmxw793HLLT",
        "outputId": "10556fad-87ed-454f-8085-bb743e901db3"
      },
      "source": [
        "print(len(dfb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GeIVDv7HmQh"
      },
      "source": [
        "10180\n",
        "test posts length:  2546"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLYzIGNxwbiU"
      },
      "source": [
        "dfb[1:2546].to_csv(\"springberttest.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTeCLREygK-"
      },
      "source": [
        "dfb[2547:10180].to_csv(\"sprintberttrain.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rTbxara5gLso",
        "outputId": "69f97211-c9eb-469d-8f30-8436acece733"
      },
      "source": [
        "#stemming\n",
        "def stem_words(text):\n",
        "    return \" \".join([porter_stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: stem_words(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like mani song favorit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>realli thank haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    posts  label\n",
              "0  like mani song favorit      0\n",
              "1                 haha jk      0\n",
              "2       realli thank haha      0\n",
              "3                              0\n",
              "4                    rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9j767afjwLv"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.metrics import f1_score ,classification_report\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl99-gZCgnLV"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['posts'], df['label'] , test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZGHK5vVgnLW",
        "outputId": "7c301db9-832e-4329-f5d8-332562ce17cc"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNOYISfSgnLW"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'.')\n",
        "count_vect.fit(df['posts'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVG3J1vIgnLW",
        "outputId": "960fba8c-dd89-4104-bf8d-e3c76b576b79"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['posts'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['posts'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['posts'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qcb308LgnLX"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufju6ycrgnLX",
        "outputId": "a07a42b5-a6da-4916-ea26-fc9bec1e6448"
      },
      "source": [
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR Accuracy, WordLevel TF-IDF: \", accuracy)\n",
        "print(\"LR F1score, WordLevel TF-IDF: \", f1score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR Accuracy, N-Gram Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR Accuracy, CharLevel Vectors: \", accuracy)\n",
        "print(\"LR F1score, N-Gram Vectors: \", f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Accuracy, WordLevel TF-IDF:  0.9481539670070699\n",
            "LR F1score, WordLevel TF-IDF:  0.9586769137424798\n",
            "LR Accuracy, N-Gram Vectors:  0.9367635506677141\n",
            "LR F1score, N-Gram Vectors:  0.9654896886602455\n",
            "LR Accuracy, CharLevel Vectors:  0.950510604870385\n",
            "LR F1score, N-Gram Vectors:  0.9608548109521645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkhgvi0Hg2IR"
      },
      "source": [
        "#Accuracy and F1 score after sentiment analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0ieus5Fi-b7z",
        "outputId": "76360165-fe38-4386-8ffb-3fa45cdc29b5"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwgOLQv_AQYp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SEVNDqUMARIv",
        "outputId": "ea1313d5-7242-4c74-ced2-7a41281b9730"
      },
      "source": [
        "#text lower\n",
        "df[\"posts\"] = df[\"posts\"].str.lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "#storing the puntuation free text\n",
        "df['posts']= df['posts'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "#removing numbers \n",
        "def remove_numbers(text):\n",
        "  output=''.join(c for c in text if not c.isdigit())\n",
        "  return output\n",
        "#applying the function\n",
        "#text=this person 100 fake beware isabella\n",
        "df['posts']= df['posts'].apply(lambda x:remove_numbers(x))\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   i like too many songs to have a favorite      0\n",
              "1                                   haha jk       0\n",
              "2                         really thanks haha      0\n",
              "3                                                 0\n",
              "4                                       rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "orHkA793ARIw",
        "outputId": "1299fd7a-3f33-4cd4-8d38-b317737fb674"
      },
      "source": [
        "#removing stop words\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: remove_stopwords(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like many songs favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      posts  label\n",
              "0  like many songs favorite      0\n",
              "1                   haha jk      0\n",
              "2        really thanks haha      0\n",
              "3                                0\n",
              "4                      rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjml8jYk2GzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0242433b-6b04-403e-d033-190e5e59c04c"
      },
      "source": [
        "#Sentiment Analysis\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "# function to print sentiments\n",
        "# of the sentence.\n",
        "def sentiment_scores(sentence):\n",
        "# Create a SentimentIntensityAnalyzer object.\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "# polarity_scores method of SentimentIntensityAnalyzer\n",
        "# oject gives a sentiment dictionary.\n",
        "# which contains pos, neg, neu, and compound scores.\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "    #print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
        "    #print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
        "    #print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
        "    #print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
        "    #print(\"Sentence Overall Rated As\", end = \" \")\n",
        "    # decide sentiment as positive, negative and neutral\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        return 1 #positive\n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "        return -1 #negative\n",
        "    else :\n",
        "        return 0 #neutral\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 30.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am0mO9P830pe",
        "outputId": "8959d803-0739-4c49-a7f3-4bc53a816f9d"
      },
      "source": [
        "# Driver code\n",
        "if __name__ == \"__main__\" :\n",
        "    print(\"Text Selected for VADER Sentimental Analysis :\")\n",
        "    sentence1 = ('''ANN is like our brain; millions and billions of cells — called neurons, which processes information in the form of electric signals. Similarly, in ANN, the network structure has an input layer, a hidden layer, and the output layer. It is also called Multi-Layer Perceptron as it has multiple layers. The hidden layer is known as a “distillation layer” that distils some critical patterns from the data/information and passes it onto the next layer. It then makes the network quicker and more productive by distinguishing the data from the data sources, leaving out the excess data.''')\n",
        "    print(sentence1)\n",
        "#sentiment_scores(sentence1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Selected for VADER Sentimental Analysis :\n",
            "ANN is like our brain; millions and billions of cells — called neurons, which processes information in the form of electric signals. Similarly, in ANN, the network structure has an input layer, a hidden layer, and the output layer. It is also called Multi-Layer Perceptron as it has multiple layers. The hidden layer is known as a “distillation layer” that distils some critical patterns from the data/information and passes it onto the next layer. It then makes the network quicker and more productive by distinguishing the data from the data sources, leaving out the excess data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HQzinzir4OT0",
        "outputId": "81ee13cf-584f-4ff1-cded-d8b9f9a8c1fe"
      },
      "source": [
        "df[\"sentiment\"] = df[\"posts\"].apply(lambda text: sentiment_scores(text))\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like many songs favorite</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sure like tell wht u wnna know like wht use</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>emma hahahahah missssseddd yuhhhhh</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>night shuree</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>alreadi answrd</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>yes veryy trustin person may help yuh</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         posts  label  sentiment\n",
              "0                     like many songs favorite      0          1\n",
              "1                                      haha jk      0          1\n",
              "2                           really thanks haha      0          1\n",
              "3                                                   0          0\n",
              "4                                         rawr      0          0\n",
              "5  sure like tell wht u wnna know like wht use      0          1\n",
              "6           emma hahahahah missssseddd yuhhhhh      0          0\n",
              "7                                 night shuree      0          0\n",
              "8                               alreadi answrd      0          0\n",
              "9        yes veryy trustin person may help yuh      0          1"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V_5YAVI5HYn9",
        "outputId": "86923450-f304-466e-da70-6bf6a2677879"
      },
      "source": [
        "df1=df[['label' ,'sentiment']]\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  sentiment\n",
              "0      0          1\n",
              "1      0          1\n",
              "2      0          1\n",
              "3      0          0\n",
              "4      0          0"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjGMzjyB8vwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f68a6b-e840-4312-bd88-d266be8ce9f5"
      },
      "source": [
        "df1['sentiment']=df1['sentiment'].astype(str)\n",
        "#df1['sentiment']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QFIgLVv0ELk",
        "outputId": "375d99a7-6e45-4bfd-ef1d-23ab242c46e9"
      },
      "source": [
        "df1['label']=df1['label'].astype(str)\n",
        "df1['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "12721    0\n",
              "12722    1\n",
              "12723    1\n",
              "12724    1\n",
              "12725    0\n",
              "Name: label, Length: 12726, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjlMbupB8wXD"
      },
      "source": [
        "df1[1:2000].to_csv(\"berttestsenti.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIQuZOFm8wXE"
      },
      "source": [
        "df1[2001:10000].to_csv(\"berttrainsenti.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOBq8WtHtlQR"
      },
      "source": [
        "df1.to_csv(\"askfm-sentiments.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED-d2bZSCWyN"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df1['label'], df1['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kVyY3vWCGPZ",
        "outputId": "4eebeebd-1c48-4391-e91d-e84628e0f8a9"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnq5obBIGwlN"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000, lowercase=False)\n",
        "tfidf_vect.fit(df1['sentiment'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "#tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "#tfidf_vect_ngram.fit(df1['sentiment'])\n",
        "#xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "#xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "#tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "#tfidf_vect_ngram_chars.fit(df1['sentiment'])\n",
        "#xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "#xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfqv_lDgjuyU"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return accuracy, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMR12Gv8kAD1",
        "outputId": "8a643ee9-7b50-4366-8d19-afccfb372658"
      },
      "source": [
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR Accuracy, WordLevel TF-IDF: \", accuracy)\n",
        "print(\"LR F1score, WordLevel TF-IDF: \", f1score)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "#accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "#print(\"LR Accuracy, N-Gram Vectors: \", accuracy)\n",
        "#print(\"LR F1score, N-Gram Vectors: \", f1score)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "#accuracy,f1score = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "#print(\"LR Accuracy, CharLevel Vectors: \", accuracy)\n",
        "#print(\"LR F1score, N-Gram Vectors: \", f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Accuracy, WordLevel TF-IDF:  0.4874312647289866\n",
            "LR F1score, WordLevel TF-IDF:  0.6252523601503464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Co5s0bKJpFv",
        "outputId": "feae66f8-d0e0-4502-d751-dda7e80c1aa8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGChMr2YshR6",
        "outputId": "5cc13d26-62e0-4479-c837-df25aab1b216"
      },
      "source": [
        "!unzip gdrive/My\\ Drive/sentiments.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/sentiments.zip\n",
            "  inflating: askfm-berttrain.csv     \n",
            "  inflating: __MACOSX/._askfm-berttrain.csv  \n",
            "  inflating: askfm-bert-test.csv     \n",
            "  inflating: __MACOSX/._askfm-bert-test.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEG3YfsgaYkv",
        "outputId": "c56ba3fd-6db0-492b-c421-2480e9957ab1"
      },
      "source": [
        "!unzip gdrive/My\\ Drive/wiki-news-300d-1M.vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWj90CgYWMx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ef34ab-bf45-4e1f-c17c-d97347b5c198"
      },
      "source": [
        "import csv\n",
        "df2=pd.read_csv('/content/wiki-news-300d-1M.vec' ,quoting=csv.QUOTE_NONE, error_bad_lines=False , delimiter=\";\")\n",
        "#df2.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 42: expected 1 fields, saw 2\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "71DIaUi76IfF",
        "outputId": "0048afdd-c390-4eb1-b67b-58120f872ef7"
      },
      "source": [
        "#Data Loading \n",
        "df=pd.read_csv('/content/FromSpring_datasets.csv' , error_bad_lines=False, delimiter=\",\") #error_bad_lines=False usecols=[\"label\",\"q_a\"]\n",
        "#df['label']=df['label'].astype('object')\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really?!?! Thanks?! haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>;(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>*RAWR*?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   I like too many songs to have a favorite      0\n",
              "1                         </3 ? haha jk! <33      0\n",
              "2                   Really?!?! Thanks?! haha      0\n",
              "3                                         ;(      0\n",
              "4                                    *RAWR*?      0"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zz8fZsr5sw2U",
        "outputId": "b198e9ed-91f7-4620-ba6c-d6183152d5cc"
      },
      "source": [
        "#text lower\n",
        "df[\"posts\"] = df[\"posts\"].str.lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "#storing the puntuation free text\n",
        "df['posts']= df['posts'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "#removing numbers \n",
        "def remove_numbers(text):\n",
        "  output=''.join(c for c in text if not c.isdigit())\n",
        "  return output\n",
        "#applying the function\n",
        "#text=this person 100 fake beware isabella\n",
        "df['posts']= df['posts'].apply(lambda x:remove_numbers(x))\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i like too many songs to have a favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       posts  label\n",
              "0   i like too many songs to have a favorite      0\n",
              "1                                   haha jk       0\n",
              "2                         really thanks haha      0\n",
              "3                                                 0\n",
              "4                                       rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "03UNYBLLsw2U",
        "outputId": "2da190b1-9929-43cd-9464-1de00039fd41"
      },
      "source": [
        "#removing stop words\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(lambda text: remove_stopwords(text))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>like many songs favorite</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>haha jk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>really thanks haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rawr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      posts  label\n",
              "0  like many songs favorite      0\n",
              "1                   haha jk      0\n",
              "2        really thanks haha      0\n",
              "3                                0\n",
              "4                      rawr      0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_IrJ_Vsw2U"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "from sklearn.metrics import f1_score ,classification_report\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT_BZ3o-sw2U"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['posts'], df['label'] , test_size=0.2, random_state=42)\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvWAjO5Tsw2U",
        "outputId": "4d58944a-e033-4333-fe90-9fb6f525c301"
      },
      "source": [
        "print('train posts length: ',len(train_x))\n",
        "print('test posts length: ',len(valid_x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train posts length:  10180\n",
            "test posts length:  2546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P647dzTsw2V"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'.')\n",
        "count_vect.fit(df['posts'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzY3YQkHsw2V",
        "outputId": "8e7955c2-5832-4474-80d0-80666b8ec143"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['posts'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['posts'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['posts'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUsQTsNEsw2V"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    #print(metrics.classification_report(valid_y, predictions, target_names=['q_a', 'label']))\n",
        "    #f1score=metrics.f1_score(predictions,valid_y , average='weighted')\n",
        "    #accuracy=metrics.accuracy_score(predictions, valid_y)\n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.f1_score(predictions,valid_y , average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukc3LgJKbWbi"
      },
      "source": [
        "# load the pre-trained word-embedding vectors \n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('/content/wiki-news-300d-1M.vec' , encoding=\"utf8\")):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
        "\n",
        "# create a tokenizer \n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(df['posts'])\n",
        "word_index = token.word_index\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
        "\n",
        "# create token-embedding mapping\n",
        "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBCLiBSkptLO",
        "outputId": "58a1eab4-c708-48b6-f654-399cfa3ef6cb"
      },
      "source": [
        "import tensorflow as tf \n",
        "def create_cnn():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the convolutional Layer\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    # Add the pooling Layer\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "classifier = create_cnn()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print(\"CNN, Word Embeddings\",  accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "319/319 [==============================] - 9s 24ms/step - loss: 0.2213\n",
            "CNN, Word Embeddings 0.9667207792207791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwFINuuu5hox",
        "outputId": "853f9e21-69b3-4c90-f831-caaa340a37b7"
      },
      "source": [
        "import tensorflow as tf \n",
        "def create_cnn():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the convolutional Layer\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    # Add the pooling Layer\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "classifier = create_cnn()\n",
        "f1score = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print(\"CNN, Word Embeddings\",  f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "319/319 [==============================] - 8s 24ms/step - loss: 0.2299\n",
            "CNN, Word Embeddings 0.9667207792207791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVuJGaX1ktpO"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}